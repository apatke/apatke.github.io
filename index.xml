<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Home on Archit Patke</title><link>https://apatke.github.io/</link><description>Recent content in Home on Archit Patke</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor> ()</managingEditor><webMaster> ()</webMaster><lastBuildDate>Wed, 19 Jul 2017 00:00:00 +0000</lastBuildDate><atom:link href="https://apatke.github.io/" rel="self" type="application/rss+xml"/><item><title>SIMPPO: A Scalable and Incremental Online Learning Framework for Serverless Resource Management</title><link>https://apatke.github.io/publications/socc22/</link><pubDate>Wed, 15 Jun 2022 00:00:00 +0000</pubDate><author> ()</author><guid>https://apatke.github.io/publications/socc22/</guid><description>&lt;p&gt;Serverless Function-as-a-Service (FaaS) offers improved programmability for customers, yet it is not server-“less” and comes at the cost of more complex infrastructure management (e.g., resource provisioning and scheduling) for cloud providers. To maintain function service-level objectives (SLOs) and improve resource utilization efficiency, recent research has been focused on applying online learning algorithms such as reinforcement learning (RL) to manage resources. Compared to rule-based solutions with heuristics, RL-based approaches eliminate humans in the loop and avoid the painstaking generation of heuristics.&lt;/p&gt;
&lt;p&gt;Despite the initial success of applying RL, we first show in this paper that the state-of-the-art single-agent RL algorithm (S-RL) suffers up to 4.8x higher p99 function latency degradation on multi-tenant serverless FaaS platforms compared to isolated environments and is unable to converge during training. We then design and implement a scalable and incremental multi-agent RL framework based on Proximal Policy Optimization (SIMPPO). Our experiments on widely used serverless benchmarks demonstrate that in multi-tenant environments, SIMPPO enables each RL agent to efficiently converge during training and provides online function latency performance comparable to that of S-RL trained in isolation (which we refer to as the baseline for assessing RL performance) with minor degradation (&amp;lt;9.2%). In addition, SIMPPO reduces the p99 function latency by 4.5x compared to S-RL in multi-tenant cases.&lt;/p&gt;</description></item><item><title>Delay Sensitivity-driven Congestion Mitigation for HPC Systems</title><link>https://apatke.github.io/publications/ics2021/</link><pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate><author> ()</author><guid>https://apatke.github.io/publications/ics2021/</guid><description>&lt;p&gt;Modern high-performance computing (HPC) systems concurrently execute multiple distributed applications that contend for the high-speed network leading to congestion. Consequently, application runtime variability and suboptimal system utilization are observedin production systems. To address these problems, we propose Netscope, a congestion mitigation framework based on a novel delay sensitivity metric that quantifies the impact of congestionon application runtime. Netscope uses delay sensitivity estimates to drive a congestion mitigation mechanism to selectively throttle applications that are less susceptible to congestion. We evaluate Netscope on two Cray Aries systems, including a production supercomputer, on common scientific applications. Our evaluation showsthat Netscope has a low training cost and accurately estimates the impact of congestion on application runtime with a correlation between 0.7 and 0.9. Moreover, Netscope reduces application tail runtime increase by up to 16.3× while improving the median systemutility by 12%.&lt;/p&gt;</description></item><item><title>Measuring Congestion in High-Performance Datacenter Interconnects</title><link>https://apatke.github.io/publications/nsdi2020/</link><pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate><author> ()</author><guid>https://apatke.github.io/publications/nsdi2020/</guid><description>&lt;p&gt;While it is widely acknowledged that network congestion
in High Performance Computing (HPC) systems can significantly degrade application performance, there has been little
to no quantification of congestion on credit-based interconnect networks. We present a methodology for detecting, extracting, and characterizing regions of congestion in networks.
We have implemented the methodology in a deployable tool,
Monet, which can provide such analysis and feedback at runtime. Using Monet, we characterize and diagnose congestion
in the world’s largest 3D torus network of Blue Waters, a 13.3-
petaflop supercomputer at the National Center for Supercomputing Applications. Our study deepens the understanding of
production congestion at a scale that has never been evaluated
before.&lt;/p&gt;</description></item><item><title>A Study of Network Congestion in Two Supercomputing High-Speed Interconnects</title><link>https://apatke.github.io/publications/hoti2019/</link><pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate><author> ()</author><guid>https://apatke.github.io/publications/hoti2019/</guid><description>&lt;p&gt;Network congestion in high-speed interconnects is
a major source of application runtime performance variation.
Recent years have witnessed a surge of interest from both
academia and industry in the development of novel approaches
for congestion control at the network level and in application
placement, mapping, and scheduling at the system-level. However,
these studies are based on proxy applications and benchmarks
that are not representative of field-congestion characteristics of
high-speed interconnects. To address this gap, we present (a) an
end-to-end framework for monitoring and analysis to support
long-term field-congestion characterization studies, and (b) an
empirical study of network congestion in petascale systems across
two different interconnect technologies: (i) Cray Gemini, which
uses a 3-D torus topology, and (ii) Cray Aries, which uses the
DragonFly topology.&lt;/p&gt;</description></item></channel></rss>