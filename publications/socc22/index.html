<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo 0.59.1"><meta name=author content="Archit Patke"><meta name=description content="SIMPPO: A Scalable and Incremental Online Learning Framework for Serverless Resource Management"><meta property="og:title" content="SIMPPO: A Scalable and Incremental Online Learning Framework for Serverless Resource Management"><meta property="og:description" content="Serverless Function-as-a-Service (FaaS) offers improved programmability for customers, yet it is not server-“less” and comes at the cost of more complex infrastructure management (e.g., resource provisioning and scheduling) for cloud providers. To maintain function service-level objectives (SLOs) and improve resource utilization efficiency, recent research has been focused on applying online learning algorithms such as reinforcement learning (RL) to manage resources. Compared to rule-based solutions with heuristics, RL-based approaches eliminate humans in the loop and avoid the painstaking generation of heuristics."><meta property="og:type" content="article"><meta property="og:url" content="https://apatke.github.io/publications/socc22/"><meta property="article:published_time" content="2022-06-15T00:00:00+00:00"><meta property="article:modified_time" content="2022-06-15T00:00:00+00:00"><meta itemprop=name content="SIMPPO: A Scalable and Incremental Online Learning Framework for Serverless Resource Management"><meta itemprop=description content="Serverless Function-as-a-Service (FaaS) offers improved programmability for customers, yet it is not server-“less” and comes at the cost of more complex infrastructure management (e.g., resource provisioning and scheduling) for cloud providers. To maintain function service-level objectives (SLOs) and improve resource utilization efficiency, recent research has been focused on applying online learning algorithms such as reinforcement learning (RL) to manage resources. Compared to rule-based solutions with heuristics, RL-based approaches eliminate humans in the loop and avoid the painstaking generation of heuristics."><meta itemprop=datePublished content="2022-06-15T00:00:00&#43;00:00"><meta itemprop=dateModified content="2022-06-15T00:00:00&#43;00:00"><meta itemprop=wordCount content="210"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="SIMPPO: A Scalable and Incremental Online Learning Framework for Serverless Resource Management"><meta name=twitter:description content="Serverless Function-as-a-Service (FaaS) offers improved programmability for customers, yet it is not server-“less” and comes at the cost of more complex infrastructure management (e.g., resource provisioning and scheduling) for cloud providers. To maintain function service-level objectives (SLOs) and improve resource utilization efficiency, recent research has been focused on applying online learning algorithms such as reinforcement learning (RL) to manage resources. Compared to rule-based solutions with heuristics, RL-based approaches eliminate humans in the loop and avoid the painstaking generation of heuristics."><title>SIMPPO: A Scalable and Incremental Online Learning Framework for Serverless Resource Management | Archit Patke</title><link rel=canonical href=https://apatke.github.io/publications/socc22/><link rel=icon href=https://apatke.github.io/img/favicon.ico><link rel="shortcut icon" href=https://apatke.github.io/img/favicon.ico><link rel=apple-touch-icon href=https://apatke.github.io/img/favicon.ico><link rel=stylesheet href=/main.min.css><link rel=preload href=https://use.fontawesome.com/releases/v5.3.1/css/all.css crossorigin=anonymous as=style onload="this.rel='stylesheet'"><link rel=preload href=https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css type=text/css as=style onload="this.rel='stylesheet'"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-167344484-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body><div class=padding id=left></div><div id=container><div id=sidebar><div id=enclose-sidebar><div id=sidebar-content><h1><a href=https://apatke.github.io/>Archit Patke</a></h1><p>PhD Student<br>Electrical and Computer Engineering<br>University of Illinois at Urbana-Champaign</p><ul class=icon-list><li><a href=mailto:apatke@illinois.edu><i class="fas fa-envelope-open fa-fw"></i></a></li><li><a href="https://illinois.edu/map/view?buildingId=148"><i class="fas fa-map-marker-alt fa-fw"></i></a></li><li><a href=https://dblp.uni-trier.de/pers/hd/p/Patke:Archit><i class="ai ai-dblp fa-fw"></i></a></li><li><a href=https://www.linkedin.com/in/archit-patke-169a46103/><i class="fab fa-linkedin fa-fw"></i></a></li><li><a href=https://github.com/apatke><i class="fab fa-github fa-fw"></i></a></li><li><a href=https://www.facebook.com/archit.patke><i class="fab fa-facebook fa-fw"></i></a></li></ul></div><div id=avatar><img src=https://apatke.github.io/img/me.jpg alt=Avatar></div></div></div><div id=content><ol class=breadcrumbs><li><a href=/><i class="fas fa-home"></i></a></li><li><a href=https://apatke.github.io/publications/>Publications</a></li><li>SIMPPO: A Scalable and Incremental Online Learning Framework for Serverless Resource Management</li></ol><div class=titlesec><h1 class=no-border>SIMPPO: A Scalable and Incremental Online Learning Framework for Serverless Resource Management</h1><h3>Haoran Qiu, Weichao Mao, **Archit Patke**, Chen Wang, Hubertus Franke, Zbigniew T. Kalbarczyk, Tamer Başar, Ravishankar K. Iyer</h3><h3 style=color:#555><b><i>**SoCC 2022**</i></b></h3></div><hr><ul class=single-paper-links><li><a href=https://dl.acm.org/doi/10.1145/3542929.3563475 target=_blank><i class="ai ai-doi" aria-hidden=true></i>&nbsp;DOI</a></li><li><a href=https://haoran-qiu.com/slides/simppo.pdf target=_blank><i class="fas fa-video" aria-hidden=true></i>&nbsp;Slides</a></li><li><a href=https://apatke.github.io/publications/socc22/Paper.pdf target=_blank><i class="far fa-file-pdf" aria-hidden=true></i>&nbsp;Paper</a></li></ul><h3>Abstract</h3><p>Serverless Function-as-a-Service (FaaS) offers improved programmability for customers, yet it is not server-“less” and comes at the cost of more complex infrastructure management (e.g., resource provisioning and scheduling) for cloud providers. To maintain function service-level objectives (SLOs) and improve resource utilization efficiency, recent research has been focused on applying online learning algorithms such as reinforcement learning (RL) to manage resources. Compared to rule-based solutions with heuristics, RL-based approaches eliminate humans in the loop and avoid the painstaking generation of heuristics.</p><p>Despite the initial success of applying RL, we first show in this paper that the state-of-the-art single-agent RL algorithm (S-RL) suffers up to 4.8x higher p99 function latency degradation on multi-tenant serverless FaaS platforms compared to isolated environments and is unable to converge during training. We then design and implement a scalable and incremental multi-agent RL framework based on Proximal Policy Optimization (SIMPPO). Our experiments on widely used serverless benchmarks demonstrate that in multi-tenant environments, SIMPPO enables each RL agent to efficiently converge during training and provides online function latency performance comparable to that of S-RL trained in isolation (which we refer to as the baseline for assessing RL performance) with minor degradation (&lt;9.2%). In addition, SIMPPO reduces the p99 function latency by 4.5x compared to S-RL in multi-tenant cases.</p></div></div><div class=padding id=right></div><script src=https://instant.page/3.0.0 type=module defer integrity=sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1 crossorigin=anonymous></script></body></html>