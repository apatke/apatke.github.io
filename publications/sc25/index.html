<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo 0.59.1"><meta name=author content="Archit Patke"><meta name=description content="Characterizing GPU resilience in modern AI systems"><meta property="og:title" content="Characterizing GPU resilience in modern AI systems"><meta property="og:description" content="In this study, we characterize GPU failures in Delta, the current large-scale AI system with over 600 petaflops of peak compute throughput. The system comprises GPU and non-GPU nodes with modern AI accelerators, such as NVIDIA A40, A100, and H100 GPUs. The study uses two and a half years of data on GPU errors. We evaluate the resilience of GPU hardware components to determine the vulnerability of different GPU components to failure and their impact on the GPU and node availability."><meta property="og:type" content="article"><meta property="og:url" content="https://apatke.github.io/publications/sc25/"><meta property="article:published_time" content="2025-07-20T00:00:00+00:00"><meta property="article:modified_time" content="2025-07-20T00:00:00+00:00"><meta itemprop=name content="Characterizing GPU resilience in modern AI systems"><meta itemprop=description content="In this study, we characterize GPU failures in Delta, the current large-scale AI system with over 600 petaflops of peak compute throughput. The system comprises GPU and non-GPU nodes with modern AI accelerators, such as NVIDIA A40, A100, and H100 GPUs. The study uses two and a half years of data on GPU errors. We evaluate the resilience of GPU hardware components to determine the vulnerability of different GPU components to failure and their impact on the GPU and node availability."><meta itemprop=datePublished content="2025-07-20T00:00:00&#43;00:00"><meta itemprop=dateModified content="2025-07-20T00:00:00&#43;00:00"><meta itemprop=wordCount content="238"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Characterizing GPU resilience in modern AI systems"><meta name=twitter:description content="In this study, we characterize GPU failures in Delta, the current large-scale AI system with over 600 petaflops of peak compute throughput. The system comprises GPU and non-GPU nodes with modern AI accelerators, such as NVIDIA A40, A100, and H100 GPUs. The study uses two and a half years of data on GPU errors. We evaluate the resilience of GPU hardware components to determine the vulnerability of different GPU components to failure and their impact on the GPU and node availability."><title>Characterizing GPU Resilience in Modern AI Systems | Archit Patke</title><link rel=canonical href=https://apatke.github.io/publications/sc25/><link rel=icon href=https://apatke.github.io/img/favicon.ico><link rel="shortcut icon" href=https://apatke.github.io/img/favicon.ico><link rel=apple-touch-icon href=https://apatke.github.io/img/favicon.ico><link rel=stylesheet href=/main.min.css><link rel=preload href=https://use.fontawesome.com/releases/v5.3.1/css/all.css crossorigin=anonymous as=style onload="this.rel='stylesheet'"><link rel=preload href=https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css type=text/css as=style onload="this.rel='stylesheet'"></head><body><div class=padding id=left></div><div id=container><div id=sidebar><div id=enclose-sidebar><div id=sidebar-content><h1><a href=https://apatke.github.io/>Archit Patke</a></h1><p>PhD Candidate<br>Electrical and Computer Engineering<br>University of Illinois at Urbana-Champaign</p><ul class=icon-list><li><a href=mailto:apatke@illinois.edu><i class="fas fa-envelope-open fa-fw"></i></a></li><li><a href="https://scholar.google.com/citations?user=NK4dg2oAAAAJ&amp;hl=en"><i class="ai ai-google-scholar-square ai-fw"></i></a></li><li><a href=https://www.linkedin.com/in/archit-patke-169a46103/><i class="fab fa-linkedin fa-fw"></i></a></li><li><a href=https://github.com/apatke><i class="fab fa-github fa-fw"></i></a></li></ul></div><div id=avatar><img src=https://apatke.github.io/img/me.jpg alt=Avatar></div></div></div><div id=content><ol class=breadcrumbs><li><a href=/><i class="fas fa-home"></i></a></li><li><a href=https://apatke.github.io/publications/>Publications</a></li><li>Characterizing GPU resilience in modern AI systems</li></ol><div class=titlesec><h1 class=no-border>Characterizing GPU resilience in modern AI systems</h1><h3>Shengkun Cui^, **Archit Patke**^, Hung Ngyuen, Aditya Ranjan, Ziheng Chen, Phuong Cao, Brett Bode, Gregory Bauer, Catello Di Martino, Saurabh Jha, Chandra Narayanaswami, Daby Sow, Zbigniew Kalbarczyk, Ravishankar Iyer</h3><h3 style=color:#555><b><i>**SC 2025**</i></b></h3></div><hr><ul class=single-paper-links><li><a href=https://arxiv.org/abs/2503.11901 target=_blank><i class="ai ai-doi" aria-hidden=true></i>&nbsp;DOI</a></li><li><a href=https://apatke.github.io/publications/sc25/Paper.pdf target=_blank><i class="far fa-file-pdf" aria-hidden=true></i>&nbsp;Paper</a></li></ul><h3>Abstract</h3><p>In this study, we characterize GPU failures in Delta, the current large-scale AI system with over 600 petaflops of peak compute throughput. The system comprises GPU and non-GPU nodes with modern AI accelerators, such as NVIDIA A40, A100, and H100 GPUs. The study uses two and a half years of data on GPU errors. We evaluate the resilience of GPU hardware components to determine the vulnerability of different GPU components to failure and their impact on the GPU and node availability. We measure the key propagation paths in GPU hardware, GPU interconnect (NVLink), and GPU memory. Finally, we evaluate the impact of the observed GPU errors on user jobs. Our key findings are: (i) Contrary to common beliefs, GPU memory is over 30x more reliable than GPU hardware in terms of MTBE (mean time between errors). (ii) The newly introduced GSP (GPU System Processor) is the most vulnerable GPU hardware component. (iii) NVLink errors did not always lead to user job failure, and we attribute it to the underlying error detection and retry mechanisms employed. (iv) We show multiple examples of hardware errors originating from one of the key GPU hardware components, leading to application failure. (v) We project the impact of GPU node availability on larger scales with emulation and find that significant overprovisioning between 5-20% would be necessary to handle GPU failures. If GPU availability were improved to 99.9%, the overprovisioning would be reduced by 4x.</p></div></div><div class=padding id=right></div><script src=https://instant.page/3.0.0 type=module defer integrity=sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1 crossorigin=anonymous></script></body></html>