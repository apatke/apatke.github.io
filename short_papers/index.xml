<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Short_papers on Archit Patke</title><link>https://apatke.github.io/short_papers/</link><description>Recent content in Short_papers on Archit Patke</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 10 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://apatke.github.io/short_papers/index.xml" rel="self" type="application/rss+xml"/><item><title>Is Function-as-a-Service a Good Fit for Latency-Critical Services?</title><link>https://apatke.github.io/short_papers/middleware/</link><pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate><guid>https://apatke.github.io/short_papers/middleware/</guid><description>Function-as-a-Service (FaaS) is becoming an increasingly popular cloud-deployment paradigm for serverless computing that frees application developers from managing the infrastructure. At the same time, it allows cloud providers to assert control in workload consolidation, i.e., co-locating multiple containers on the same server, thereby achieving higher server utilization, often at the cost of higher end-toend function request latency. Interestingly, a key aspect of serverless latency management has not been well studied: the trade-off between application developers’ latency goals and the FaaS providers’ utilization goals.</description></item><item><title>Modeling Communication Latency in High-speed Interconnection Networks</title><link>https://apatke.github.io/short_papers/nsdi2020/</link><pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate><guid>https://apatke.github.io/short_papers/nsdi2020/</guid><description>Estimating performance degradation due to network congestion in data centers is important for identifying andmitigating sources/effects of contention. We propose a model-driven methodology that estimates performance degradationexperienced by applications in the presence of congestion. Using Gaussian Linear models to approximate latency from networkperformance counters we were able to correctly estimate 89% ofcompletion times within a 35% error bound.</description></item></channel></rss>